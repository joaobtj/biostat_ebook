

# Análise de Variância

Os procedimentos t de duas amostras comparam as médias de duas populações ou as respostas médias a dois tratamentos em um experimento.

Naturalmente, os estudos nem sempre comparam apenas dois grupos. Precisamos de um método que compare qualquer quantidade de médias.


## Comparação de várias médias

Os métodos estatísticos para se lidar com comparações múltiplas geralmente apresentam dois passos:

1.Um teste geral para verificarmos se há boa evidência de quaisquer diferenças entre os parâmetros que desejamos comparar.

2.Uma análise de acompanhamento detalhada para decidirmos quais parâmetros são diferentes e estimarmos o tamanho das diferenças.

## A ideia da Análise de Variância

Considere a população com 150 árvores pertencente a um reflorestamento de Mogno Africano (Capítulo 6).

Suponha que retiremos 5 amostras aleatórias desta população com 8 indivíduos em cada amostra.

```{r, include=FALSE}
dap <- readr::read_csv("https://biostat.tolentino.pro.br/data/dap.csv")
library(dplyr)

set.seed("21102015")
dap5_wide <- dap$dap %>%
  sample(40) %>%
  matrix(ncol = 5) %>%
  as.data.frame() %>%
  rename(
    am1 = V1,
    am2 = V2,
    am3 = V3,
    am4 = V4,
    am5 = V5
  )
```

```{r, echo=FALSE}
gt::gt(dap5_wide)
```


```{r, include=FALSE}
dap5 <- dap5_wide %>%
  tidyr::pivot_longer(cols = 1:5, names_to = "amostra", values_to = "dap")

readr::write_csv(dap5, "data/dap5.csv")
```



Estes dados podem ser encontrados no arquivo [dap5.csv](data/dap5.csv)

Uma Análise de Variância pode ser executada com as funções `lm` e `anova`, como a seguir:

```{r}

aov_dap5 <- lm(dap ~ amostra, data = dap5)
anova(aov_dap5)
```


```{r include=FALSE}
pvalor <- anova(aov_dap5)$`Pr(>F)`[1]
```

Queremos testar a hipótese nula de que não há diferenças entre os diâmetros médios das cinco populações de onde as amostras foram retiradas:

H~0~:μ~1~ = μ~2~ = μ~3~ = μ~~4 = μ~5~

A hipótese alternativa é a de que há alguma diferença, isto é, nem todas as três médias populacionais são iguais:

H~1~: nem todas as médias μ são iguais

A priori, sabemos que as cinco amostras foram aleatoriamente retiradas da mesma população. Logo, o teste F da Análise de Variância é não significativo (como esperado). Seu p-valor foi de `r pvalor %>% round(3)` e, por isso, não rejeitamos a hipótese H~0~, ou seja, não há evidências que os diâmetros médios das amostras sejam diferentes ou que venham de populações diferentes.

Mas o que occoreria se houvesse um efeito aditivo em cada uma das amostras?
Vamos supor que a amostra 1 tenha um efeito aditivo de +5 unidades no DAP. A amostra 2 de -5, a amostra 3 de +3, a amostra 4 de +2 e, por fim, a amostra 5 não tenha nenhum efeito aditivo. O resultado é este mostrado no arquivo [dap5p.csv](data/dap5p.csv)

```{r, include=FALSE}

efeito <- c(5, -5, 3, 2, 0)
dap5p_wide <- dap5_wide + rep(efeito, e = 8)
```


```{r, echo=FALSE}
gt::gt(dap5p_wide)
```


```{r, include=FALSE}

dap5p <- dap5p_wide %>%
  tidyr::pivot_longer(cols = 1:5, names_to = "amostra", values_to = "dap")

readr::write_csv(dap5p, "data/dap5p.csv")
```


A Análise de Variância, com estes valores atualizados, fica assim:

```{r}
aov_dap5p <- lm(dap ~ amostra, data = dap5p)
anova(aov_dap5p)
```

```{r, include=FALSE}
pvalorp <- anova(aov_dap5p)$`Pr(>F)`[1]
```


Para as mesmas hipóteses anteriores, o teste F da Análise de Variância é significativo (p-valor ~ `r pvalorp %>% round(3)`). Neste caso, rejeitamos a hipótese H~0~ e podemos concluir que há evidências de que as amostras tenham médias de diâmetro diferentes ou que seja oriundas de populações diferentes.


## Análise de Variância para um fator

:::{.example #anova1 name="Análise de Variância para um fator"}

Pesquisadores estudaram a relação entre variedades da flor tropical *Heliconia*, na ilha de Dominica, e as diferentes espécies de beija-flores que fertilizam essas flores.

Acredita-se que os comprimentos das flores e as formas dos bicos dos beija-flores evoluíram juntos e se adaptaram uns aos outros.

Se isso for verdade, as variedades de flores fertilizadas por diferentes espécies de beija-flores devem ter diferentes distribuições de comprimentos.

O arquivo [bflor.xlsx](data/bflor.xlsx) fornece as medidas de comprimentos (em milímetros, mm) para amostras de três variedades de *Heliconia*, cada uma fertilizada por uma espécie diferente de beija-flor. As espécies são:

1. *Heliconia bihai*
1. *Heliconia caribaea* vermelha
1. *Heliconia caribaea* amarela

Em particular, os comprimentos médios de suas flores são diferentes?

As três variedades têm distribuições com comprimentos diferentes?


Queremos testar a hipótese nula de que não há diferenças entre os comprimentos médios das três populações de flores:

H~0~: μ~1~ = μ~2~ = μ~3~

A hipótese alternativa é a de que há alguma diferença, isto é, nem todas as três médias populacionais são iguais:

H~1~: nem todas as μ~1~, μ~2~ e μ~3~ são iguais


Iniciemos com uma análise exploratória: 

```{r}
bflor <- readxl::read_excel("data/bflor.xlsx") %>%
  mutate(especie = factor(especie))


bflor %>%
  group_by(especie) %>%
  summarise(
    n = n(),
    media = mean(comprimento),
    desvpad = sd(comprimento),
    var = var(comprimento)
  )


boxplot(comprimento ~ especie, data = bflor)
```

Efetuamos a Análise de Variância propriamente dita:

```{r}
aov_bflor <- lm(comprimento ~ especie, data = bflor)

anova(aov_bflor)
```
**CONCLUSÃO**: Há forte evidência de que as três variedades de flores não tenham, todas, o mesmo comprimento médio.

O teste F não diz quais das três médias são significantemente diferentes. Aparentemente, pela nossa análise de dados preliminar, as flores da bihai são visivelmente maiores que as da vermelha ou da amarela.

As flores vermelhas e amarelas são muito próximas, mas as vermelhas tendem a ser mais compridas.

:::

## Condições para a ANOVA

1. Temos k AASs independentes, uma de cada uma das k populações.

Como de costume, o planejamento da produção dos dados é a condição mais importante para inferência. Uma amostragem viesada ou confundimento pode tornar qualquer inferência sem sentido.

2. Cada uma das k populações tem uma distribuição Normal com média desconhecida

Procedimentos para comparação de médias não são muito sensíveis à falta de Normalidade. A Anova torna-se mais segura à medida que os tamanhos das amostras aumentam. Quando não houver valores atípicos e as distribuições forem aproximadamente simétricas, podemos usar a Anova com segurança.

3. Todas as populações têm o mesmo desvio-padrão $\sigma$, de valor desconhecido.

A terceira condição é problemática. Não é fácil verificar a condição de igualdade dos desvios-padrão populacionais. 
Testes estatísticos de igualdade dos desvios-padrão são tão sensíveis à ausência de Normalidade que, na prática, têm pouco valor.

Mas, qual é a gravidade de os desvios-padrão serem desiguais?

A Anova não é muito sensível a violações da condição, particularmente quando todas as amostras têm tamanhos iguais ou semelhantes e nenhuma delas é muito pequena.
Ao planejar um estudo, tente tomar amostras do mesmo tamanho aproximado de todos os grupos que pretende comparar e não utilize amostras muito pequenas.

Certifique-se, antes de fazer a Anova, de que os desvios-padrão amostrais sejam, pelo menos, semelhantes entre si.
Como regra prática: maior desvio-padrão não seja o dobro (ou triplo) do menor.


:::{.example #press2 name="Verificação do pressuposto da Normalidade"}

.

```{r}
## curtose
aov_bflor %>%
  residuals() %>%
  moments::kurtosis()

## assimetria
aov_bflor %>%
  residuals() %>%
  moments::skewness()

## Teste de Shapiro-Wilk
aov_bflor %>%
  residuals() %>%
  shapiro.test()


## Gráfico dos quantis normais
aov_bflor %>%
  residuals() %>%
  qqnorm()
aov_bflor %>%
  residuals() %>%
  qqline()


## Histograma
aov_bflor %>%
  residuals() %>%
  hist()


## Ramo e folhas
aov_bflor %>%
  residuals() %>%
  stem()
```

.

:::


Pela análise do conjunto dos resultados acima, não há evidência de desvio severo da Normalidade.

:::{.example #press3 name="Verificação do pressuposto da homogeneidade das variâncias"}

.

```{r}


## razão maior/menor desvio-padrão
bflor %>%
  group_by(especie) %>%
  summarise(desvpad = sd(comprimento)) %>%
  mutate(razao = max(desvpad) / desvpad)

## boxplot condicional dos resíduos
boxplot(residuals(aov_bflor) ~ especie, data = bflor)

## resíduos vs ajustados
plot(aov_bflor, 1)

## teste de Bartlett
bartlett.test(residuals(aov_bflor) ~ especie, data = bflor)

## teste de Levene
car::leveneTest(residuals(aov_bflor) ~ especie, data = bflor)
```

Pela análise do conjunto dos resultados acima, não há evidência de não homogeneidade das variâncias.


:::


## Testes de acompanhamento

Para sabermos quais tratamentos diferem entre si, utilizamos um teste de acompanhamento (teste *post hoc*).

Entre os mais utilizados, serão tratados neste capítulo os seguintes testes:

* Teste de Dunnett
* Teste de Tukey
* Contrastes ortogonais

### Teste de Dunnett

Testa os contrastes envolvendo o(s) tratamento(s) testemunha (ou controle ou placebo).



:::{.example #dunnett name="Teste de Dunnett"}


A homeopatia procura utilizar pequenas doses de substâncias altamente diluídas e geralmente perigosas. Cientistas advertem que há pouca evidência que apoie a homeopatia como tratamento eficaz para qualquer condição específica, exceto para uns poucos estudos.

Em um desses estudos, os pesquisadores fizeram e suturaram uma incisão muscular profunda em ratos anestesiados e, então, associaram-nos aleatoriamente a um de cinco tratamentos:

1. Arnica - dose alta
1. Arnica - dose baixa
1. Estafisagria - dose alta
1. Estafisagria - dose baixa
1. Placebo

As feridas eram examinadas diariamente para se determinar o tempo (em dias) até sua completa cicatrização. Os valores estão no arquivo [homeopatia.xlsx](data/homeopatia.xlsx)

Há evidência significante de que o tempo de cicatrização dependa do tratamento recebido?

```{r, include=FALSE}
hom <- readxl::read_excel("data/homeopatia.xlsx") %>%
  mutate(remedio = factor(remedio))
aov_hom <- lm(tempo~remedio, data=hom) #lm ou glm
anova(aov_hom)
```

Após efetuada a Análise de Variância e verificados os pressupostos^[Análise não mostrada aqui.], segue-se com o teste de Dunnett

```{r}


dn_remedio <- emmeans::emmeans(aov_hom, ~remedio, contr="dunnett", 
                                ref=which(names(table(hom$remedio))=="Placebo"))


## contrastes
dn_remedio$contrasts

## intervalo de confiança
dn_remedio$contrasts %>% confint()

## plot
dn_remedio$emmeans %>% plot()
```



```{r, echo=FALSE}
dn_remedio$emmeans

library(gt)
dn_remedio$emmeans %>%
  as.data.frame() %>%
  select(remedio, emmean)  %>%

  bind_cols(g=c("*","*","*","*","")) %>%
  gt() %>%
  fmt_number(
    columns = emmean,
    decimals = 2
  )  %>%
  cols_label(
    remedio = "Remédio",
    emmean = "Tempo de Cicatrização (dias)",
    g=""
  ) %>%
  cols_align(columns = remedio,
             align = "left") %>%
  cols_align(columns = emmean,
             align = "center") %>%
  cols_align(columns = g,
             align = "left") %>%
  tab_footnote(
    footnote = "Médias seguidas por * diferem do tratamento placebo pelo teste de Dunnett (p<0,05).",
  ) %>%
  tab_header(title = md("Tabela X. Tempo de cicatrização médio (dias) para uma profunda ferida cirúrgica tratada com remédios homeopáticos."),)

```

Pelo teste de Dunnett, verifica-se que todos os remédios homeopáticos levaram a um tempo de cicatrização menor do que o tratamento placebo.

:::

### Teste de Tukey

Criado por John Tukey (1915–2000), realiza todos os contrastes (comparações) possíveis entre as médias populacionais mantendo o nível de significância.

Em lugar do teste *t*, utiliza o valor crítico *m*, que depende do número de populações, do número de observações e do nível de significância.

As hipóteses testadas são:

H~0~: μ~i~ = μ~j~

H~1~: μ~i~ ≠ μ~j~

para todas as médias populacionais

Ainda, há muitos outros teste de comparações múltiplas similares ao teste de Tukey. Se você é capaz de interpretar os resultado deste teste, será capaz de entender os resultados de muitos outros.


:::{.example #tukey name="Teste de Tukey"}

Voltando ao exemplo anterior das Flores de *Heliconia* ^[Lembre-se de calcular a Análise de Variância antes de efetuar os testes de acompanhamento.].

Utilizaremos o pacote *emmeans* para o cálculo do teste de Tukey.

```{r}

tk_especie <- emmeans::emmeans(aov_bflor, ~especie, contr = "tukey")

## contrastes
tk_especie$contrasts

## Intervalo de confiança
tk_especie$contrasts %>% confint()

## letras (CLD)
tk_especie$emmeans %>% multcomp::cld(Letters = letters)

## plot
tk_especie$emmeans %>% plot()
```

A Tabela abaixo mostra um exemplo de como os resultados do teste podem ser apresentados.


```{r, echo=FALSE}
lt <- tk_especie$emmeans %>% multcomp::cld(Letters = letters)
library(gt)
tk_especie$emmeans %>%
  as.data.frame() %>%
  select(especie, emmean) %>%
  bind_cols(g = lt$.group) %>%
  gt() %>%
  fmt_number(
    columns = emmean,
    decimals = 2
  ) %>%
  cols_label(
    especie = "Espécie",
    emmean = "Comprimento (mm)",
    g = ""
  ) %>%
  cols_align(columns = especie,
             align = "left") %>%
  cols_align(columns = emmean,
             align = "center") %>%
  cols_align(columns = g,
             align = "left") %>%
  tab_footnote(
    footnote = "Médias seguidas por letras iguais não diferem entre si pelo teste de Tukey (p<0,05).",
  ) %>%
  tab_header(
    title = md("Tabela X. Comprimento médio (mm) de flores de três espécies do gênero *Heliconia*.")
    )
```



Podemos concluir que as flores da variedade *H. bihai* tem maior comprimento que as demais. As flores de *H. caribaea* vermelha são maiores que *H. caribaea* amarela. Esta última tem o menor comprimento entre todas.


:::



